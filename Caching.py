import numpy as np
from FiducciaMattheyses.FiducciaMattheyses import FiducciaMattheyses
from Dataset.DatasetH5 import DatasetH5
from math import ceil

__author__ = 'gm'


class Caching:
    def __init__(self, pruning_matrix: np.ndarray, dataset_path: str, cache_size: int):
        """
        :param pruning_matrix: the pruning matrix generated by PruningMatrix.py
        :type pruning_matrix: np.ndarray
        :param dataset_path: hdf5 database path
        :type dataset_path: str
        :param cache_size: the capacity of the cache. This number indicates how many time-series can fit in memory
        :type cache_size: int
        """
        self.pm = pruning_matrix
        self.dataset_path = dataset_path
        self.cache_size = cache_size
        self.ds = DatasetH5(dataset_path)
        self.batches = [[x for x in range(pruning_matrix.shape[0])]]
        self.total_batches = 1
        self.total_ts = len(self.ds)

    # TODO: how to merge very small batches together (fast)?
    def calculate_batches(self):
        if self.total_batches >= 2 * ceil(self.total_ts / self.cache_size):  # M > ⌈2n/B⌉
            return
        temp_batches = []
        for batch in self.batches:
            fm = FiducciaMattheyses()
            fm.input_routine(self.pm, batch)
            a, b = fm.find_mincut()
            self.total_batches += 1
            temp_batches.append(a)
            temp_batches.append(b)
        self.batches = temp_batches
        self.calculate_batches()

        return self.batches






